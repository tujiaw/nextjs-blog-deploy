---
title: "构建高效的 AI Agent"
date: 2026-01-14
tags: ["AI", "Agent", "Anthropic", "LLM"]
summary: "Anthropic 分享了与客户合作构建 LLM Agent 的经验，介绍了从简单可组合模式到自主 Agent 的最佳实践，包括工作流模式、构建块和实际应用案例。"
draft: false
---

> 本文翻译自 Anthropic 官方博客：[Building Effective AI Agents](https://www.anthropic.com/engineering/building-effective-agents)
>
> 译者注：本文是 Anthropic Agent 开发最佳实践系列的第一篇，介绍了 Agent 开发的基础架构模式。

在过去一年中，我们与数十个团队合作，跨行业构建大型语言模型（LLM）Agent。最成功的实现都没有使用复杂的框架或专门的库。相反，它们使用的是简单的、可组合的模式。

在本文中，我们将分享与客户合作以及自己构建 Agent 所学到的经验，并为开发者提供构建高效 Agent 的实用建议。

## 什么是 Agent？

"Agent" 可以用多种方式定义。一些客户将 Agent 定义为在扩展时间内独立运行、使用各种工具完成复杂任务的完全自主系统。另一些客户则用这个词来描述遵循预定义工作流的更规范的实现。在 Anthropic，我们将所有这些变体都归类为 **Agent 系统（agentic systems）**，但在 **工作流（workflows）** 和 **Agent** 之间做了一个重要的架构区分：

- **工作流** 是 LLM 和工具通过预定义代码路径进行编排的系统。
- **Agent** 则是 LLM 动态指导自己的流程和工具使用，保持对如何完成任务控制的系统。

下面，我们将详细探讨这两种类型的 Agent 系统。在附录 1（"实践中的 Agent"）中，我们描述了客户在使用这类系统时发现特别有价值的两个领域。

## 何时（以及何时不）使用 Agent

在使用 LLM 构建应用程序时，我们建议找到尽可能简单的解决方案，只在需要时增加复杂性。这可能意味着根本不构建 Agent 系统。Agent 系统通常以延迟和成本为代价来换取更好的任务性能，你应该考虑这种权衡何时有意义。

当需要更多复杂性时，工作流为明确定义的任务提供可预测性和一致性，而 Agent 则是需要大规模灵活性和模型驱动决策时的更好选择。然而，对于许多应用程序，通过检索和上下文示例优化单个 LLM 调用通常就足够了。

## 何时以及如何使用框架

有许多框架使 Agent 系统更容易实现，包括：

- Claude Agent SDK
- AWS 的 Strands Agents SDK
- Rivet，一个拖放式 GUI LLM 工作流构建器
- Vellum，另一个用于构建和测试复杂工作流的 GUI 工具

这些框架通过简化调用 LLM、定义和解析工具以及链式调用等标准低级任务，使入门变得容易。然而，它们通常创建额外的抽象层，可能会掩盖底层提示和响应，使它们更难调试。它们也可能使添加复杂性变得诱人，而更简单的设置就足够了。

我们建议开发者首先直接使用 LLM API：许多模式可以用几行代码实现。如果你确实使用框架，确保你理解底层代码。对底层代码的错误假设是客户错误的常见来源。

请参阅我们的 cookbook 了解一些示例实现。

## 构建块、工作流和 Agent

在本节中，我们将探讨我们在生产中看到的 Agent 系统的常见模式。我们将从基础构建块——增强型 LLM——开始，逐步增加复杂性，从简单的组合工作流到自主 Agent。

### 构建块：增强型 LLM

Agent 系统的基本构建块是通过检索、工具和内存等增强功能增强的 LLM。我们当前的模型可以主动使用这些能力——生成自己的搜索查询、选择适当的工具，并确定要保留哪些信息。

![增强型 LLM](https://www-cdn.anthropic.com/images/4zrzovbb/website/d3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png)

我们建议关注实现的两个关键方面：将这些能力定制到你的特定用例，并确保它们为你的 LLM 提供简单、文档完善的接口。虽然有许多方法可以实现这些增强功能，一种方法是通过我们最近发布的模型上下文协议（Model Context Protocol），它允许开发者通过简单的客户端实现与不断增长的第三方工具生态系统集成。

在本文的其余部分，我们将假设每个 LLM 调用都可以访问这些增强能力。

### 工作流：提示链（Prompt Chaining）

提示链将任务分解为一系列步骤，每个 LLM 调用处理前一个的输出。你可以在任何中间步骤添加程序化检查（参见下图中的"门"）以确保过程仍然在轨道上。

![提示链工作流](https://www-cdn.anthropic.com/images/4zrzovbb/website/7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png)

**何时使用此工作流：** 当任务可以容易清晰地分解为固定的子任务时，此工作流是理想的选择。主要目标是通过使每个 LLM 调用成为更容易的任务，来以延迟换取更高的准确性。

**提示链有用的示例：**

- 生成营销文案，然后将其翻译成不同的语言。
- 编写文档大纲，检查大纲是否符合某些标准，然后根据大纲编写文档。

### 工作流：路由（Routing）

路由对输入进行分类并将其引导到专门的后续任务。此工作流允许分离关注点，并构建更专门的提示。没有此工作流，针对一种输入的优化可能会损害其他输入的性能。

![路由工作流](https://www-cdn.anthropic.com/images/4zrzovbb/website/5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png)

**何时使用此工作流：** 路由适用于复杂任务，其中存在不同类别最好分开处理，并且分类可以由 LLM 或更传统的分类模型/算法准确处理。

**路由有用的示例：**

- 将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具。
- 将简单/常见问题引导到更小、成本效率高的模型（如 Claude Haiku 4.5），将困难/不寻常问题引导到更强大的模型（如 Claude Sonnet 4.5）以优化最佳性能。

### 工作流：并行化（Parallelization）

LLM 有时可以同时处理一个任务并以程序化方式聚合其输出。此工作流（并行化）表现为两个关键变体：

- **分段（Sectioning）**：将任务分解为并行运行的独立子任务。
- **投票（Voting）**：多次运行同一任务以获得不同的输出。

![并行化工作流](https://www-cdn.anthropic.com/images/4zrzovbb/website/406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png)

**何时使用此工作流：** 当划分的子任务可以并行化以提高速度，或者需要多个视角或尝试以获得更高置信度的结果时，并行化是有效的。对于具有多个考虑因素的复杂任务，当每个考虑因素由单独的 LLM 调用处理时，LLM 通常表现得更好，允许专注于每个特定方面。

**并行化有用的示例：**

- **分段**：
  - 实现防护栏，其中一个模型实例处理用户查询，另一个检查不当内容或请求。这倾向于比让同一个 LLM 调用同时处理防护栏和核心响应表现得更好。
  - 自动化评估以评估 LLM 性能，其中每个 LLM 调用评估模型在给定提示上的不同方面性能。
- **投票**：
  - 审查一段代码是否存在漏洞，其中几个不同的提示审查代码并在发现问题时标记。
  - 评估给定内容是否不当，多个提示评估不同方面或需要不同的投票阈值以平衡误报和漏报。

### 工作流：编排器-工作者（Orchestrator-Workers）

在编排器-工作者工作流中，中央 LLM 动态分解任务，将其委托给工作者 LLM，并综合它们的结果。

![编排器-工作者工作流](https://www-cdn.anthropic.com/images/4zrzovbb/website/8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png)

**何时使用此工作流：** 此工作流适用于复杂任务，你无法预测所需的子任务（例如，在编码中，需要更改的文件数量和每个文件中更改的性质可能取决于任务）。尽管在拓扑上相似，但与并行化的关键区别在于其灵活性——子任务不是预定义的，而是由编排器根据特定输入确定的。

**编排器-工作者有用的示例：**

- 每次对多个文件进行复杂更改的编码产品。
- 涉及从多个源收集和分析信息以寻找可能相关信息的搜索任务。

### 工作流：评估器-优化器（Evaluator-Optimizer）

在评估器-优化器工作流中，一个 LLM 调用生成响应，而另一个在循环中提供评估和反馈。

![评估器-优化器工作流](https://www-cdn.anthropic.com/images/4zrzovbb/website/14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png)

**何时使用此工作流：** 当我们有明确的评估标准，并且迭代细化提供可衡量的价值时，此工作流特别有效。适合的两个标志是，首先，当人类表达他们的反馈时 LLM 响应可以明显改进；其次，LLM 可以提供这种反馈。这类似于人类作家在制作精致文档时可能经历的迭代写作过程。

**评估器-优化器有用的示例：**

- 文学翻译，其中译者 LLM 最初可能无法捕捉到细微差别，但评估器 LLM 可以提供有用的批评。
- 复杂的搜索任务，需要多轮搜索和分析以收集全面信息，评估器决定是否需要进一步搜索。

### Agent

Agent 正随着 LLM 在关键能力上成熟——理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复——而在生产中出现。Agent 的工作始于来自人类用户的命令或交互式讨论。一旦任务明确，Agent 就会自主规划和操作，可能会返回给人类以获取更多信息或判断。在执行过程中，Agent 在每一步从环境获取"基本真值"（如工具调用结果或代码执行）以评估其进展至关重要。然后，Agent 可以在检查点或遇到障碍时暂停以获取人类反馈。任务通常在完成时终止，但也很常见包括停止条件（如最大迭代次数）以保持控制。

Agent 可以处理复杂的任务，但它们的实现通常很直接。它们通常只是基于环境反馈在循环中使用工具的 LLM。因此，清晰而深思熟虑地设计工具集及其文档至关重要。我们将在附录 2（"提示工程你的工具"）中扩展工具开发的最佳实践。

![自主 Agent](https://www-cdn.anthropic.com/images/4zrzovbb/website/58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png)

**何时使用 Agent：** Agent 可以用于开放性问题，其中很难或无法预测所需的步骤数量，并且你无法硬编码固定路径。LLM 可能会运行许多轮，你必须对其决策有一定的信任。Agent 的自主性使它们成为在可信环境中扩展任务的理想选择。

Agent 的自主性质意味着更高的成本，以及复合错误的潜在可能性。我们建议在沙盒环境中进行大量测试，以及适当的防护栏。

**Agent 有用的示例：**

以下示例来自我们自己的实现：

- 一个编码 Agent 用于解决 SWE-bench 任务，这涉及根据任务描述对许多文件进行编辑。
- 我们的"计算机使用"参考实现，其中 Claude 使用计算机完成任务。

![编码 Agent 的高级流程](https://www-cdn.anthropic.com/images/4zrzovbb/website/4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png)

## 组合和定制这些模式

这些构建块不是规范性的。它们是开发者可以塑造和组合以适应不同用例的常见模式。与任何 LLM 功能一样，成功的关键是衡量性能并迭代实现。重申：你应该只在明显改善结果时才增加复杂性。

## 总结

在 LLM 领域的成功不在于构建最复杂的系统。而在于为你的需求构建**正确的**系统。从简单的提示开始，通过全面的评估优化它们，只有当更简单的解决方案不足时才添加多步 Agent 系统。

在实现 Agent 时，我们尝试遵循三个核心原则：

1. 在 Agent 的设计中保持**简单性**。
2. 通过明确显示 Agent 的规划步骤来优先考虑**透明度**。
3. 通过彻底的工具**文档和测试**精心设计你的 Agent-计算机接口（ACI）。

框架可以帮助你快速入门，但在进入生产时不要犹豫减少抽象层并使用基本组件构建。通过遵循这些原则，你可以创建不仅强大而且可靠、可维护且受其用户信任的 Agent。

### 致谢

由 Erik Schluntz 和 Barry Zhang 撰写。这项工作借鉴了我们在 Anthropic 构建 Agent 的经验以及客户分享的有价值见解，我们深表感谢。

## 附录 1：实践中的 Agent

我们与客户的工作揭示了两个特别有前景的 AI Agent 应用，展示了上述讨论的模式的实际价值。这两个应用都说明了 Agent 如何为需要对话和行动、具有明确成功标准、允许反馈循环并集成有意义的人类监督的任务增加最大价值。

### A. 客户支持

客户支持通过工具集成将熟悉的聊天机器人界面与增强功能相结合。对于更开放的 Agent 来说，这是一个自然的契合，因为：

- 支持交互自然地遵循对话流程，同时需要访问外部信息和行动。
- 可以集成工具来提取客户数据、订单历史和知识库文章。
- 诸如发放退款或更新票据等操作可以通过程序化处理。
- 成功可以通过用户定义的解决方案清楚地衡量。

几家通过基于使用情况的定价模型（仅对成功的解决方案收费）展示了这种方法的可行性，显示了对其 Agent 有效性的信心。

### B. 编码 Agent

软件开发领域显示了 LLM 功能的显著潜力，能力从代码完成演变为自主问题解决。Agent 特别有效，因为：

- 代码解决方案可以通过自动化测试验证。
- Agent 可以使用测试结果作为反馈迭代解决方案。
- 问题空间定义明确且结构化。
- 输出质量可以客观衡量。

在我们自己的实现中，Agent 现在可以仅根据拉取请求描述解决 SWE-bench Verified 基准中的真实 GitHub 问题。然而，虽然自动化测试有助于验证功能，但人工审查对于确保解决方案符合更广泛的系统要求仍然至关重要。

## 附录 2：提示工程你的工具

无论你正在构建哪种 Agent 系统，工具都可能是 Agent 的重要组成部分。工具使 Claude 能够通过在我们的 API 中指定其精确结构和定义来与外部服务和 API 交互。当 Claude 响应时，如果它计划调用工具，它将在 API 响应中包含工具使用块。工具定义和规范应该与你的整体提示一样受到关注。在这个简短的附录中，我们描述如何提示工程你的工具。

通常有几种方法可以指定相同的操作。例如，你可以通过编写 diff 或通过重写整个文件来指定文件编辑。对于结构化输出，你可以将代码返回在 markdown 或 JSON 中。在软件工程中，像这样的差异是表面的，可以无损地从一种转换为另一种。然而，某些格式对 LLM 来说比其他格式更难编写。编写 diff 需要在编写新代码之前知道块头中有多少行正在更改。在 JSON 中编写代码（与 markdown 相比）需要对换行符和引号进行额外转义。

我们关于决定工具格式的建议如下：

- 给模型足够的"思考"令牌，然后再将自己写入角落。
- 保持格式接近模型在互联网上文本中自然看到的格式。
- 确保没有格式"开销"，比如必须准确计数数千行代码，或转义它编写的任何代码。

一个经验法则是考虑在人机界面（HCI）上投入多少精力，并计划在创建良好的 **Agent**-计算机接口（ACI）上投入同样多的精力。以下是一些关于如何这样做的想法：

- 设身处地为模型着想。基于描述和参数，如何使用这个工具是显而易见的，还是你需要仔细思考？如果是这样，那么模型可能也是如此。一个好的工具定义通常包括示例用法、边缘情况、输入格式要求，以及与其他工具的明确边界。
- 如何更改参数名称或描述以使事情更明显？将此视为为团队中的初级开发者编写一个很棒的 docstring。
- 测试模型如何使用你的工具：在我们的工作台中运行许多示例输入，看看模型犯了什么错误，然后迭代。
- 为你的工具进行防错设计（Poka-yoke）。更改参数，使犯错更难。

在为 SWE-bench 构建 Agent 时，我们实际上花费了更多时间优化我们的工具而不是整体提示。例如，我们发现模型在使用相对文件路径的工具时会犯错误，在 Agent 移出根目录之后。为了解决这个问题，我们将工具更改为始终需要绝对文件路径——我们发现模型完美地使用了这种方法。
